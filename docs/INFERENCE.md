# Inference (Batch/Streaming)

Windowed processing, posterior updates, early exit, calibration, OOD.
